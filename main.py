"""
–°–µ—Ä–≤–∏—Å –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ë–î —Å –ø–æ–º–æ—â—å—é LLM
–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: FastAPI + Kafka + PostgreSQL
"""

# main.py
import asyncio
import json
import logging
import sys
import uuid
from contextlib import asynccontextmanager
from typing import Any, Optional

from aiokafka import AIOKafkaProducer
from fastapi import FastAPI, HTTPException
from psycopg2.extras import Json, RealDictCursor
from psycopg2.pool import ThreadedConnectionPool
from pydantic import BaseModel

from src.config import Config


def setup_logging():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    # –°–æ–∑–¥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä
    formatter = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )

    # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π —Ö–µ–Ω–¥–ª–µ—Ä
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)

    # –§–∞–π–ª–æ–≤—ã–π —Ö–µ–Ω–¥–ª–µ—Ä
    file_handler = logging.FileHandler("app.log", encoding="utf-8")
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(formatter)

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG)
    root_logger.addHandler(console_handler)
    root_logger.addHandler(file_handler)

    # –£–º–µ–Ω—å—à–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
    logging.getLogger("aiokafka").setLevel(logging.WARNING)
    logging.getLogger("kafka").setLevel(logging.WARNING)
    logging.getLogger("urllib3").setLevel(logging.WARNING)

    return logging.getLogger(__name__)


logger = setup_logging()


# === –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö ===


class AnalysisRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ë–î"""

    url: str
    ddl: list[Any]
    queries: list[Any]
    pass


class TaskResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å ID –∑–∞–¥–∞—á–∏"""

    taskid: str


class StatusResponse(BaseModel):
    """–°—Ç–∞—Ç—É—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏"""

    taskid: str
    status: str  # pending, processing, completed, failed
    progress: Optional[int] = None  # –ø—Ä–æ—Ü–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (0-100)


class ResultResponse(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞"""

    taskid: str
    status: str
    result: Optional[dict] = None
    error: Optional[str] = None


# === –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö ===


def get_db_pool():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —Å PostgreSQL"""
    logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —Å PostgreSQL")
    try:
        pool = ThreadedConnectionPool(
            Config.DB_POOL_MIN,
            Config.DB_POOL_MAX,
            host=Config.POSTGRES_HOST,
            port=Config.POSTGRES_PORT,
            database=Config.POSTGRES_DB,
            user=Config.POSTGRES_USER,
            password=Config.POSTGRES_PASSWORD,
        )
        logger.info(
            f"–ü—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ (min={Config.DB_POOL_MIN}, max={Config.DB_POOL_MAX})"
        )
        return pool
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {e}")
        raise


def init_db_schema(pool):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –≤ –ë–î"""
    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ö–µ–º—ã –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
    conn = pool.getconn()
    try:
        with conn.cursor() as cur:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS tasks (
                    task_id UUID PRIMARY KEY,
                    status VARCHAR(50) NOT NULL,
                    created_at TIMESTAMP DEFAULT NOW(),
                    updated_at TIMESTAMP DEFAULT NOW(),
                    request_data JSONB,
                    result_data JSONB,
                    error_message TEXT,
                    progress INTEGER DEFAULT 0
                )
            """)
            conn.commit()
        logger.info("–°—Ö–µ–º–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å—Ö–µ–º—ã –ë–î: {e}")
        raise
    finally:
        pool.putconn(conn)


# === Lifespan —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ ===


@asynccontextmanager
async def lifespan(app: FastAPI):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    # Startup
    logger.info("–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")

    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Kafka Producer")
    app.state.kafka_producer = AIOKafkaProducer(
        bootstrap_servers=Config.KAFKA_BOOTSTRAP_SERVERS,
        value_serializer=lambda v: json.dumps(v).encode("utf-8"),
    )

    max_retries = 10
    retry_delay = 3

    for attempt in range(1, max_retries + 1):
        try:
            await app.state.kafka_producer.start()
            break
        except Exception as e:
            logger.error(
                f"‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_retries} –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Kafka –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}"
            )
            if attempt < max_retries:
                logger.info(f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {retry_delay} —Å–µ–∫—É–Ω–¥...")
                await asyncio.sleep(retry_delay)
            else:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Kafka –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")
                raise

    logger.info(f"üöÄ –ü—Ä–æ–¥—é—Å–µ—Ä –≥–æ—Ç–æ–≤ –ø–∏–Ω–¥—é—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ '{Config.KAFKA_TOPIC}'...")

    try:
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Connection Pool")
        app.state.db_pool = get_db_pool()
        init_db_schema(app.state.db_pool)
        logger.info("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω–æ")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ connection pool: {e}")
        raise

    yield

    # Shutdown
    logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")
    try:
        await app.state.kafka_producer.stop()
        logger.info("Kafka Producer –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        app.state.db_pool.closeall()
        logger.info("–ü—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –∑–∞–∫—Ä—ã—Ç")
        logger.info("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: {e}")


# === FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ ===

app = FastAPI(title="LLM DB Analysis Service", lifespan=lifespan)


@app.post("/new", response_model=TaskResponse)
async def create_task(request: AnalysisRequest):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏ –Ω–∞ –∞–Ω–∞–ª–∏–∑ –ë–î
    """
    task_id = str(uuid.uuid4())
    logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏ {task_id}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–¥–∞—á—É –≤ –ë–î —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º pending
    conn = app.state.db_pool.getconn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO tasks (task_id, status, request_data)
                VALUES (%s, %s, %s)
            """,
                (task_id, "pending", Json(request.model_dump())),
            )
            conn.commit()
        logger.info(f"–ó–∞–¥–∞—á–∞ {task_id} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –ë–î —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º 'pending'")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∑–∞–¥–∞—á–∏ {task_id} –≤ –ë–î: {e}")
        raise HTTPException(status_code=500, detail="Failed to create task in database")
    finally:
        app.state.db_pool.putconn(conn)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –≤ Kafka
    message = {
        "task_id": task_id,
        "body": request.dict(),
    }

    try:
        await app.state.kafka_producer.send(Config.KAFKA_TOPIC, message)
        logger.info(f"–ó–∞–¥–∞—á–∞ {task_id} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –≤ Kafka —Ç–æ–ø–∏–∫ '{Config.KAFKA_TOPIC}'")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∑–∞–¥–∞—á–∏ {task_id} –≤ Kafka: {e}")
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ Kafka, –ø–æ–º–µ—á–∞–µ–º –∑–∞–¥–∞—á—É –∫–∞–∫ failed
        conn = app.state.db_pool.getconn()
        try:
            with conn.cursor() as cur:
                cur.execute(
                    """
                    UPDATE tasks 
                    SET status = %s, error_message = %s, updated_at = NOW()
                    WHERE task_id = %s
                """,
                    ("failed", f"Kafka error: {str(e)}", task_id),
                )
                conn.commit()
            logger.warning(f"–ó–∞–¥–∞—á–∞ {task_id} –ø–æ–º–µ—á–µ–Ω–∞ –∫–∞–∫ 'failed' –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ Kafka")
        finally:
            app.state.db_pool.putconn(conn)
        raise HTTPException(status_code=500, detail="Failed to queue task")

    return TaskResponse(taskid=task_id)


@app.get("/status", response_model=StatusResponse)
async def get_status(taskid: str):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏
    """
    logger.info(f"–ó–∞–ø—Ä–æ—Å —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏ {taskid}")

    conn = app.state.db_pool.getconn()
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(
                """
                SELECT task_id, status, progress
                FROM tasks
                WHERE task_id = %s
            """,
                (taskid,),
            )
            row = cur.fetchone()
    finally:
        app.state.db_pool.putconn(conn)

    if not row:
        logger.warning(f"–ó–∞–¥–∞—á–∞ {taskid} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        raise HTTPException(status_code=404, detail="Task not found")

    logger.info(
        f"–°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ {taskid}: {row['status']} (–ø—Ä–æ–≥—Ä–µ—Å—Å: {row['progress']}%)"
    )

    return StatusResponse(
        taskid=str(row["task_id"]), status=row["status"], progress=row["progress"]
    )


@app.get("/getresult", response_model=ResultResponse)
async def get_result(taskid: str):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏
    """
    logger.info(f"–ó–∞–ø—Ä–æ—Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∑–∞–¥–∞—á–∏ {taskid}")

    conn = app.state.db_pool.getconn()
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(
                """
                SELECT task_id, status, result_data, error_message
                FROM tasks
                WHERE task_id = %s
            """,
                (taskid,),
            )
            row = cur.fetchone()
    finally:
        app.state.db_pool.putconn(conn)

    if not row:
        logger.warning(f"–ó–∞–¥–∞—á–∞ {taskid} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        raise HTTPException(status_code=404, detail="Task not found")

    if row["status"] not in ["completed", "failed"]:
        logger.info(f"–ó–∞–¥–∞—á–∞ {taskid} –µ—â–µ –Ω–µ –≥–æ—Ç–æ–≤–∞ (—Å—Ç–∞—Ç—É—Å: {row['status']})")
        raise HTTPException(
            status_code=400,
            detail=f"Task is not ready. Current status: {row['status']}",
        )

    if row["status"] == "completed":
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞—á–∏ {taskid} —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω")
    else:
        logger.info(f"–ó–∞–¥–∞—á–∞ {taskid} –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–æ–π: {row['error_message']}")

    return ResultResponse(
        taskid=str(row["task_id"]),
        status=row["status"],
        result=row["result_data"],
        error=row["error_message"],
    )
